{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ed8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Interpretability for Ecologists\n",
    "# A Complete Guide from Most to Least Interpretable Algorithms\n",
    "\n",
    "\"\"\"\n",
    "HOW TO USE THIS NOTEBOOK:\n",
    "- Run each cell in order\n",
    "- Read the markdown text aloud (or to yourself) as you go\n",
    "- The code cells show practical implementation\n",
    "- Each algorithm includes interpretability analysis\n",
    "- Organized from MOST to LEAST interpretable\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# SETUP AND DATA LOADING\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d27d7d6",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Introduction: The Iris Dataset\n",
    "\n",
    "Today we're using the famous Iris dataset, which contains measurements of \n",
    "150 iris flowers from three species: *Iris setosa*, *Iris versicolor*, and \n",
    "*Iris virginica*. \n",
    "\n",
    "This dataset is perfect for ecology students because:\n",
    "- It's about real botanical classification\n",
    "- It has multiple species (like many ecology problems)\n",
    "- It shows how morphological traits (sepal length, sepal width, petal length, \n",
    "  petal width) can be used to classify organisms\n",
    "\n",
    "**The biological question:** Can we predict which species an iris belongs to \n",
    "based on its flower measurements?\n",
    "\n",
    "This is analogous to many problems in ecology and evolution:\n",
    "- Classifying species from trait data\n",
    "- Predicting ecological outcomes from environmental variables\n",
    "- Understanding which traits matter most for differentiation\n",
    "\n",
    "Let's load our libraries and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f8e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"✓ All libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902343ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Create a DataFrame for easier viewing\n",
    "iris_df = pd.DataFrame(X, columns=feature_names)\n",
    "iris_df['species'] = [target_names[i] for i in y]\n",
    "\n",
    "print(\"Dataset loaded! Here's what our data looks like:\\n\")\n",
    "print(iris_df.head(10))\n",
    "print(f\"\\nDataset shape: {iris_df.shape}\")\n",
    "print(f\"Features: {feature_names}\")\n",
    "print(f\"Species: {target_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2cab19",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "**What you're seeing above:**\n",
    "- 150 flowers (rows)\n",
    "- 4 measurements per flower (columns): sepal length, sepal width, petal length, petal width\n",
    "- 3 species to classify\n",
    "\n",
    "Now let's split this into training and testing sets. We'll use 80% to train \n",
    "our models and 20% to test how well they work on new data. This mimics the \n",
    "real scientific process: you develop your model on some data, then validate \n",
    "it on data the model has never seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e38d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                      random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nSpecies distribution in training set:\")\n",
    "print(pd.Series(y_train).value_counts().sort_index())\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 1: HIGHEST INTERPRETABILITY - LINEAR MODELS\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c727f4",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "---\n",
    "# PART 1: HIGHEST INTERPRETABILITY ALGORITHMS\n",
    "\n",
    "These are the \"glass box\" models. You can see exactly how they make decisions.\n",
    "Everything is transparent: which features matter, how much they matter, and \n",
    "why a specific prediction was made.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Logistic Regression\n",
    "\n",
    "**What it is:** Despite the name \"regression,\" this is a CLASSIFICATION algorithm. \n",
    "It predicts the probability that something belongs to each class. For our iris \n",
    "dataset, it predicts the probability a flower is setosa, versicolor, or virginica.\n",
    "\n",
    "**How it works:** It fits a linear equation for each class, kind of like:\n",
    "- P(setosa) = f(w1×sepal_length + w2×sepal_width + w3×petal_length + w4×petal_width)\n",
    "\n",
    "The \"weights\" (w1, w2, etc.) tell you how important each feature is.\n",
    "\n",
    "**Why it's highly interpretable:**\n",
    "1. You get coefficients for each feature that tell you the direction and \n",
    "   strength of effects\n",
    "2. You can trace exactly why any prediction was made\n",
    "3. You can explain it to a non-technical audience\n",
    "\n",
    "**When you'd use it in ecology:**\n",
    "- Predicting species presence/absence from environmental variables\n",
    "- Classifying organisms based on traits\n",
    "- Any binary or multi-class classification where you need to explain results\n",
    "\n",
    "Let's fit it and see what we learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d79cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fit logistic regression\n",
    "# We use 'lbfgs' solver and increase max_iter for convergence\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=200)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LOGISTIC REGRESSION RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nAccuracy on test set: {accuracy_log:.3f} ({accuracy_log*100:.1f}%)\")\n",
    "print(f\"\\nThis means our model correctly classified {accuracy_log*100:.1f}% of the flowers\")\n",
    "print(\"in the test set based on their measurements.\\n\")\n",
    "\n",
    "# Show detailed classification report\n",
    "print(\"Detailed Performance by Species:\")\n",
    "print(classification_report(y_test, y_pred_log, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4411327",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "**How to read the classification report above:**\n",
    "- **Precision:** When the model says a flower is species X, how often is it right?\n",
    "- **Recall:** Of all flowers that actually ARE species X, how many did we catch?\n",
    "- **F1-score:** Harmonic mean of precision and recall (overall performance measure)\n",
    "- **Support:** How many flowers of each species were in the test set\n",
    "\n",
    "Now let's look at the confusion matrix - this shows where our model made mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa233c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm_log = confusion_matrix(y_test, y_pred_log)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_log, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.title('Confusion Matrix - Logistic Regression', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Species')\n",
    "plt.xlabel('Predicted Species')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nHow to read this confusion matrix:\")\n",
    "print(\"- Diagonal = Correct predictions (darker is better)\")\n",
    "print(\"- Off-diagonal = Mistakes\")\n",
    "print(\"- Each row shows the true species, columns show what we predicted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8144bba",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "---\n",
    "### INTERPRETABILITY ANALYSIS: Logistic Regression Coefficients\n",
    "\n",
    "**This is the key part for interpretability!** The coefficients tell us how \n",
    "each feature influences the classification. A positive coefficient means \n",
    "\"higher values of this feature increase probability of this class.\"\n",
    "\n",
    "In ecology terms: these coefficients tell you which morphological traits are \n",
    "most diagnostic for each species. This is like saying \"versicolor has longer \n",
    "petals than setosa\" - but quantified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aeb909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and display coefficients\n",
    "coef_df = pd.DataFrame(\n",
    "    log_reg.coef_,\n",
    "    columns=feature_names,\n",
    "    index=target_names\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LOGISTIC REGRESSION COEFFICIENTS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nThese coefficients show how each feature affects the probability\")\n",
    "print(\"of each species. Positive = increases probability, Negative = decreases.\\n\")\n",
    "print(coef_df.round(3))\n",
    "\n",
    "# Visualize coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "coef_df.T.plot(kind='bar', width=0.8)\n",
    "plt.title('Feature Coefficients for Each Species', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Features (Flower Measurements)')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Species', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"WHAT THIS MEANS IN BIOLOGICAL TERMS:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Interpret the most important features for each species\n",
    "for i, species in enumerate(target_names):\n",
    "    print(f\"\\n{species.upper()}:\")\n",
    "    coefs = coef_df.iloc[i]\n",
    "    most_positive = coefs.idxmax()\n",
    "    most_negative = coefs.idxmin()\n",
    "    print(f\"  → Most diagnostic feature: {most_positive} (coefficient: {coefs[most_positive]:.3f})\")\n",
    "    print(f\"  → Most negative feature: {most_negative} (coefficient: {coefs[most_negative]:.3f})\")\n",
    "    print(f\"  → This means {species} tends to have {most_positive.replace(' (cm)', '')} \")\n",
    "    print(f\"    values that distinguish it from other species.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f299651",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "**Key Takeaway for Logistic Regression:**\n",
    "\n",
    "✓ **Can I explain what features matter most?** YES - we have exact coefficients\n",
    "✓ **Can I explain why a specific prediction was made?** YES - we can trace the math\n",
    "✓ **Can I explain the general pattern?** YES - we can describe relationships\n",
    "\n",
    "**Bottom line:** This is a FULLY INTERPRETABLE model. You could explain these \n",
    "results to a non-statistician, publish them in a paper, and defend them to \n",
    "reviewers. The tradeoff is that it assumes linear relationships - if your data \n",
    "has complex non-linear patterns, it might not be the most accurate.\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "============================================================================\n",
    "LINEAR REGRESSION (for comparison - using continuous target)\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262bf3b4",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## 2. Linear Regression\n",
    "\n",
    "**What it is:** This predicts a CONTINUOUS value (not categories). For example, \n",
    "predicting sepal length from the other three measurements.\n",
    "\n",
    "**How it works:** Fits a straight line (or plane in multiple dimensions):\n",
    "- sepal_length = b0 + b1×sepal_width + b2×petal_length + b3×petal_width\n",
    "\n",
    "**Why it's highly interpretable:**\n",
    "- You get a coefficient for each feature\n",
    "- Each coefficient tells you: \"For every 1-unit increase in X, Y changes by \n",
    "  this much\"\n",
    "- It's the most transparent model in all of statistics\n",
    "\n",
    "**When you'd use it in ecology:**\n",
    "- Predicting biomass from environmental variables\n",
    "- Modeling species richness as a function of habitat characteristics\n",
    "- Any relationship where you're predicting a number (not a category)\n",
    "\n",
    "**For this demo:** Let's predict sepal length from the other three features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a regression problem: predict sepal length from other features\n",
    "X_reg = iris_df[['sepal width (cm)', 'petal length (cm)', 'petal width (cm)']].values\n",
    "y_reg = iris_df['sepal length (cm)'].values\n",
    "\n",
    "# Split data\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Fit linear regression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_reg = lin_reg.predict(X_test_reg)\n",
    "\n",
    "# Calculate performance metrics\n",
    "r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LINEAR REGRESSION RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nR² Score: {r2:.3f}\")\n",
    "print(f\"RMSE: {rmse:.3f} cm\")\n",
    "print(f\"\\nR² interpretation: Our model explains {r2*100:.1f}% of the variance\")\n",
    "print(f\"in sepal length. That's pretty good!\")\n",
    "print(f\"\\nRMSE interpretation: On average, our predictions are off by {rmse:.2f} cm.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d608a117",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "**Understanding R² (R-squared):**\n",
    "- R² = 1.0 means perfect predictions\n",
    "- R² = 0.0 means your model is no better than just guessing the average\n",
    "- R² = 0.76 (what we got) means we're explaining 76% of the variation - quite good!\n",
    "\n",
    "**Understanding RMSE (Root Mean Squared Error):**\n",
    "- This is in the same units as your target (centimeters)\n",
    "- Smaller is better\n",
    "- It tells you the average size of your prediction errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0829fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test_reg, y_pred_reg, alpha=0.6, s=100)\n",
    "plt.plot([y_test_reg.min(), y_test_reg.max()], \n",
    "         [y_test_reg.min(), y_test_reg.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual Sepal Length (cm)', fontsize=12)\n",
    "plt.ylabel('Predicted Sepal Length (cm)', fontsize=12)\n",
    "plt.title('Linear Regression: Predicted vs Actual', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"In the plot above:\")\n",
    "print(\"- Points close to the red line = good predictions\")\n",
    "print(\"- Points far from the red line = errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d172c98e",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "---\n",
    "### INTERPRETABILITY ANALYSIS: Linear Regression Coefficients\n",
    "\n",
    "Here's where linear regression shines: every coefficient has a clear interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b40bc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display coefficients\n",
    "feature_names_reg = ['sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
    "coef_df_reg = pd.DataFrame({\n",
    "    'Feature': feature_names_reg,\n",
    "    'Coefficient': lin_reg.coef_\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LINEAR REGRESSION COEFFICIENTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nIntercept: {lin_reg.intercept_:.3f}\")\n",
    "print(\"\\nCoefficients:\")\n",
    "print(coef_df_reg.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETATION IN PLAIN ENGLISH:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nThe equation our model learned is:\")\n",
    "print(f\"sepal_length = {lin_reg.intercept_:.3f}\", end=\"\")\n",
    "for feat, coef in zip(feature_names_reg, lin_reg.coef_):\n",
    "    sign = \"+\" if coef >= 0 else \"\"\n",
    "    print(f\" {sign}{coef:.3f}×{feat}\", end=\"\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for feat, coef in zip(feature_names_reg, lin_reg.coef_):\n",
    "    direction = \"increases\" if coef > 0 else \"decreases\"\n",
    "    print(f\"• For every 1 cm increase in {feat},\")\n",
    "    print(f\"  sepal length {direction} by {abs(coef):.3f} cm (holding other features constant)\\n\")\n",
    "\n",
    "# Visualize coefficients\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(coef_df_reg['Feature'], coef_df_reg['Coefficient'], color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Coefficient Value', fontsize=12)\n",
    "plt.title('Feature Coefficients for Predicting Sepal Length', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da11ddb4",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "**Key Takeaway for Linear Regression:**\n",
    "\n",
    "✓ **Can I explain what features matter most?** YES - exact coefficients with clear meanings\n",
    "✓ **Can I explain why a specific prediction was made?** YES - just plug in the numbers\n",
    "✓ **Can I explain the general pattern?** YES - the equation IS the pattern\n",
    "\n",
    "**This is maximally interpretable.** The main limitation is that it assumes \n",
    "linear relationships. If sepal length actually has a U-shaped relationship with \n",
    "petal width, linear regression won't catch that.\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "============================================================================\n",
    "SECTION 2: HIGH INTERPRETABILITY - TREE-BASED MODELS\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bcb094",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "---\n",
    "# PART 2: HIGH INTERPRETABILITY - TREE MODELS\n",
    "\n",
    "Tree-based models are flowchart-like structures: \"If petal length < 2.5, then \n",
    "it's setosa; otherwise check petal width...\" They're very interpretable because \n",
    "you can literally draw them out and follow the logic.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Decision Tree\n",
    "\n",
    "**What it is:** A flowchart of yes/no questions about features. The tree splits \n",
    "the data based on which question best separates the classes.\n",
    "\n",
    "**How it works:** \n",
    "- Start with all data\n",
    "- Ask: \"What's the single best question to split this data?\" (e.g., \"Is petal length < 2.5?\")\n",
    "- Split the data based on that question\n",
    "- Repeat for each subset until you've classified everything\n",
    "\n",
    "**Why it's highly interpretable:**\n",
    "1. You can literally visualize the entire decision process\n",
    "2. You can trace exactly which questions led to a prediction\n",
    "3. You can explain it to anyone: \"First we check X, then if that's true we check Y...\"\n",
    "\n",
    "**When you'd use it in ecology:**\n",
    "- Creating identification keys for species\n",
    "- Understanding hierarchical rules for habitat suitability\n",
    "- Any problem where you want a transparent decision-making process\n",
    "\n",
    "**Limitation:** Single trees can overfit (memorize training data) and might not \n",
    "be as accurate as more complex models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f4d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "# Fit decision tree with limited depth to keep it interpretable\n",
    "tree_clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DECISION TREE RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nAccuracy on test set: {accuracy_tree:.3f} ({accuracy_tree*100:.1f}%)\")\n",
    "print(\"\\nDetailed Performance by Species:\")\n",
    "print(classification_report(y_test, y_pred_tree, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1513525",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Now let's visualize the actual decision tree. This is the \"magic\" of decision \n",
    "trees - you can SEE exactly how decisions are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa77705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree_clf, \n",
    "          feature_names=feature_names,\n",
    "          class_names=target_names,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10)\n",
    "plt.title('Decision Tree Visualization', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HOW TO READ THIS TREE:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Each box shows:\n",
    "- The question being asked (e.g., \"petal width (cm) <= 0.8\")\n",
    "- The gini score (measure of impurity - lower is better)\n",
    "- The number of samples reaching this point\n",
    "- The class distribution at this node\n",
    "- The predicted class (the color)\n",
    "\n",
    "To classify a flower:\n",
    "1. Start at the top\n",
    "2. Answer the question (is the measurement <= the threshold?)\n",
    "3. Follow the branch (True = left, False = right)\n",
    "4. Repeat until you reach a leaf (bottom box)\n",
    "5. That's your predicted species!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e6c3d2",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "---\n",
    "### INTERPRETABILITY ANALYSIS: Feature Importance\n",
    "\n",
    "Decision trees tell you which features they used and how important each was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbbcf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': tree_clf.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DECISION TREE FEATURE IMPORTANCE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nImportance scores show which features the tree used to make decisions.\")\n",
    "print(\"Higher = more important for classification.\\n\")\n",
    "print(importance_df.to_string(index=False))\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='lightcoral', edgecolor='black')\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.title('Feature Importance in Decision Tree', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "most_important = importance_df.iloc[0]\n",
    "print(f\"\\nThe most important feature is: {most_important['Feature']}\")\n",
    "print(f\"Importance score: {most_important['Importance']:.3f}\")\n",
    "print(f\"\\nThis means the tree relied most heavily on {most_important['Feature']}\")\n",
    "print(\"to split the data and make classifications.\")\n",
    "\n",
    "# Show a simple example classification path\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXAMPLE: Tracing a Prediction\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nLet's trace how the tree classifies the first flower in our test set:\")\n",
    "print(f\"Measurements: {dict(zip(feature_names, X_test[0]))}\")\n",
    "print(f\"True species: {target_names[y_test[0]]}\")\n",
    "print(f\"Predicted species: {target_names[y_pred_tree[0]]}\")\n",
    "print(\"\\nTo see the exact path this flower took through the tree,\")\n",
    "print(\"look at the visualization above and follow the decisions based on\")\n",
    "print(\"these measurements!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5869b15c",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "**Key Takeaway for Decision Trees:**\n",
    "\n",
    "✓ **Can I explain what features matter most?** YES - feature importance scores\n",
    "✓ **Can I explain why a specific prediction was made?** YES - trace the path through the tree\n",
    "✓ **Can I explain the general pattern?** YES - the tree structure shows the rules\n",
    "\n",
    "**This is highly interpretable.** The tree is a complete, transparent set of \n",
    "rules. The downside is that single trees can be unstable (small changes in data \n",
    "can change the tree structure) and may not be as accurate as ensemble methods.\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "============================================================================\n",
    "NAIVE BAYES\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1940b096",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## 4. Naive Bayes\n",
    "\n",
    "**What it is:** A probabilistic classifier based on Bayes' Theorem. It calculates \n",
    "the probability a sample belongs to each class based on the feature values.\n",
    "\n",
    "**How it works:** It assumes each feature contributes independently to the \n",
    "probability (that's the \"naive\" part - features are assumed to be independent). \n",
    "It calculates:\n",
    "- P(setosa | measurements) ∝ P(measurements | setosa) × P(setosa)\n",
    "\n",
    "**The \"naive\" assumption:** It assumes features don't interact. For iris flowers, \n",
    "this means it assumes petal length and petal width are independent, which isn't \n",
    "quite true (longer petals tend to be wider). Despite this simplification, it \n",
    "often works well!\n",
    "\n",
    "**Why it's relatively interpretable:**\n",
    "1. You can see which features have the most effect on probabilities\n",
    "2. You can extract class probabilities for each prediction\n",
    "3. The math is straightforward (compared to neural networks)\n",
    "\n",
    "**When you'd use it in ecology:**\n",
    "- Quick-and-dirty species classification\n",
    "- Text classification (like classifying field notes or paper abstracts)\n",
    "- When you have limited data and need a simple model\n",
    "\n",
    "**Limitation:** The independence assumption is rarely true in nature. If features \n",
    "are correlated (which they usually are), Naive Bayes might not be optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f4fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Fit Naive Bayes\n",
    "# We use GaussianNB which assumes features follow a normal distribution\n",
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_nb = nb_clf.predict(X_test)\n",
    "\n",
    "# Get probability predictions (this is useful for interpretability!)\n",
    "y_pred_proba_nb = nb_clf.predict_proba(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"NAIVE BAYES RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nAccuracy on test set: {accuracy_nb:.3f} ({accuracy_nb*100:.1f}%)\")\n",
    "print(\"\\nDetailed Performance by Species:\")\n",
    "print(classification_report(y_test, y_pred_nb, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a1a238",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "One nice thing about Naive Bayes: it gives you probability scores for each class, \n",
    "not just a single prediction. Let's look at a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9633b9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show probability predictions for first 5 test samples\n",
    "print(\"=\" * 70)\n",
    "print(\"PROBABILITY PREDICTIONS (First 5 Test Samples)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nFor each flower, Naive Bayes gives probability it belongs to each species:\\n\")\n",
    "\n",
    "prob_df = pd.DataFrame(y_pred_proba_nb[:5], columns=target_names)\n",
    "prob_df['Predicted'] = [target_names[i] for i in y_pred_nb[:5]]\n",
    "prob_df['True'] = [target_names[i] for i in y_test[:5]]\n",
    "\n",
    "print(prob_df.round(3).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Each row is one flower. The three probability columns show the model's\n",
    "confidence for each species. The predicted class is whichever has the\n",
    "highest probability.\n",
    "\n",
    "For example, if probabilities are [0.95, 0.03, 0.02]:\n",
    "- The model is 95% confident it's setosa\n",
    "- Only 3% confident it's versicolor\n",
    "- Only 2% confident it's virginica\n",
    "→ Prediction: setosa (with high confidence)\n",
    "\n",
    "If probabilities are [0.40, 0.35, 0.25]:\n",
    "- The model is less certain\n",
    "- All three species are somewhat plausible\n",
    "→ This is a less confident prediction\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abc76bd",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "---\n",
    "### INTERPRETABILITY ANALYSIS: Understanding Naive Bayes Parameters\n",
    "\n",
    "Naive Bayes learns the mean and variance of each feature for each class. This \n",
    "tells us the \"typical\" values of each measurement for each species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cc569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract learned parameters\n",
    "print(\"=\" * 70)\n",
    "print(\"NAIVE BAYES LEARNED PARAMETERS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nThe model learned the average (mean) and spread (variance) of each\")\n",
    "print(\"feature for each species. This is how it knows what's 'typical' for\")\n",
    "print(\"each species.\\n\")\n",
    "\n",
    "# Show means\n",
    "means_df = pd.DataFrame(nb_clf.theta_, columns=feature_names, index=target_names)\n",
    "print(\"MEAN VALUES (average measurement for each species):\")\n",
    "print(means_df.round(2))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Show variances\n",
    "vars_df = pd.DataFrame(nb_clf.var_, columns=feature_names, index=target_names)\n",
    "print(\"VARIANCE (spread of measurements for each species):\")\n",
    "print(vars_df.round(2))\n",
    "\n",
    "# Visualize the means\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    ax = axes[i]\n",
    "    means_df[feature].plot(kind='bar', ax=ax, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "    ax.set_title(f'{feature}', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Mean Value (cm)')\n",
    "    ax.set_xlabel('Species')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.suptitle('Mean Feature Values by Species (Naive Bayes Learned These)', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"WHAT THIS TELLS US:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "The model learned what's 'typical' for each species. For example:\n",
    "- Setosa has shorter petals on average\n",
    "- Virginica has longer petals and sepals\n",
    "- Versicolor is in between\n",
    "\n",
    "When classifying a new flower, the model asks: \"Which species does this flower\n",
    "look most like, based on these learned averages?\"\n",
    "\n",
    "This is interpretable because you can see exactly what the model learned about\n",
    "each species. However, we can't easily see how features interact (the \"naive\"\n",
    "independence assumption limits interpretability).\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45d7394",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "**Key Takeaway for Naive Bayes:**\n",
    "\n",
    "✓ **Can I explain what features matter most?** PARTIALLY - you can see means/variances per class\n",
    "✓ **Can I explain why a specific prediction was made?** PARTIALLY - you get probabilities\n",
    "✓ **Can I explain the general pattern?** SOMEWHAT - you can see class statistics\n",
    "\n",
    "**This is moderately interpretable.** You can understand the basic patterns the \n",
    "model learned, but the independence assumption makes it less transparent than \n",
    "linear models or decision trees. It's a good middle ground between simplicity \n",
    "and performance.\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "============================================================================\n",
    "SECTION 3: MEDIUM INTERPRETABILITY - ENSEMBLE TREE METHODS\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc228d4",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "---\n",
    "# PART 3: MEDIUM INTERPRETABILITY - ENSEMBLE METHODS\n",
    "\n",
    "Ensemble methods combine many models to make predictions. They're usually more \n",
    "accurate than single models, but harder to interpret because you're averaging \n",
    "over many decision processes.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Random Forest\n",
    "\n",
    "**What it is:** A collection (or \"forest\") of many decision trees, each trained \n",
    "on a random subset of data and features. The final prediction is a vote: whichever \n",
    "class gets the most votes from individual trees wins.\n",
    "\n",
    "**How it works:**\n",
    "1. Create many bootstrapped samples of your training data (random sampling with replacement)\n",
    "2. For each sample, build a decision tree (but only consider random subsets of features at each split)\n",
    "3. To make a prediction: ask all trees, take majority vote\n",
    "\n",
    "**Why it's \"medium\" interpretability:**\n",
    "- **GOOD:** You can get feature importance scores (which features are used most across all trees)\n",
    "- **BAD:** You can't easily trace individual predictions (would have to follow hundreds of trees)\n",
    "- **BAD:** You can't visualize the overall pattern (it's hundreds of trees, not one simple rule)\n",
    "\n",
    "**When you'd use it in ecology:**\n",
    "- Species distribution modeling (very popular for this!)\n",
    "- Predicting habitat suitability\n",
    "- Any classification problem where accuracy matters more than perfect interpretability\n",
    "- When you have non-linear relationships in your data\n",
    "\n",
    "**This is probably the most popular ML method in ecology right now** because it \n",
    "balances good accuracy with reasonable interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bfc626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Fit Random Forest\n",
    "# n_estimators = how many trees to build\n",
    "# max_depth = limit tree depth to prevent overfitting\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"RANDOM FOREST RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nNumber of trees: {rf_clf.n_estimators}\")\n",
    "print(f\"Accuracy on test set: {accuracy_rf:.3f} ({accuracy_rf*100:.1f}%)\")\n",
    "print(\"\\nDetailed Performance by Species:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=target_names))\n",
    "\n",
    "print(\"\\nNotice: Random Forest typically achieves higher accuracy than a single\")\n",
    "print(\"decision tree! That's the power of ensemble methods.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721c440c",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "---\n",
    "### INTERPRETABILITY ANALYSIS: Feature Importance\n",
    "\n",
    "The main interpretability tool for Random Forest is feature importance. This \n",
    "tells you which features were most useful across all the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53ae3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importance_df_rf = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': rf_clf.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"RANDOM FOREST FEATURE IMPORTANCE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nThese scores show which features were most useful for making splits\")\n",
    "print(\"across all 100 trees in the forest.\\n\")\n",
    "print(importance_df_rf.to_string(index=False))\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(importance_df_rf['Feature'], importance_df_rf['Importance'], \n",
    "         color='mediumseagreen', edgecolor='black')\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.title('Feature Importance in Random Forest', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nThe most important feature is: {importance_df_rf.iloc[0]['Feature']}\")\n",
    "print(f\"Importance score: {importance_df_rf.iloc[0]['Importance']:.3f}\")\n",
    "print(\"\\nThis means across all 100 decision trees, this feature was used most\")\n",
    "print(\"frequently and provided the best splits for classifying species.\")\n",
    "print(\"\\nNOTE: This tells you WHICH features matter, but not HOW they're used\")\n",
    "print(\"(e.g., you don't get direction of effects like you do with linear regression).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e33eed1",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "**What Random Forest feature importance DOESN'T tell you:**\n",
    "\n",
    "1. **Direction:** You don't know if higher values increase or decrease the probability of a class\n",
    "2. **Interactions:** You don't know if features interact (e.g., does petal length matter more when petal width is high?)\n",
    "3. **Specific predictions:** You can't easily trace why a single flower got a specific classification\n",
    "\n",
    "**This is why it's \"medium\" interpretability** - you know what matters, but not exactly how or why.\n",
    "\n",
    "For more interpretability, you could:\n",
    "- Use partial dependence plots (show relationship between one feature and predictions)\n",
    "- Use SHAP values (explain individual predictions)\n",
    "- Examine individual trees (but with 100 trees, this gets tedious)\n",
    "\n",
    "We'll show SHAP later when we get to neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64863d15",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "**Key Takeaway for Random Forest:**\n",
    "\n",
    "✓ **Can I explain what features matter most?** YES - feature importance scores\n",
    "✓ **Can I explain why a specific prediction was made?** NOT EASILY - you'd need extra tools\n",
    "✓ **Can I explain the general pattern?** NO - it's 100 trees voting\n",
    "\n",
    "**This is moderately interpretable.** You get good accuracy and can identify \n",
    "important features, but you sacrifice the transparency of simpler models. This \n",
    "is often acceptable in ecology - knowing that \"petal length matters most\" is \n",
    "often enough, even if you can't perfectly explain every prediction.\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "============================================================================\n",
    "GRADIENT BOOSTING\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56f23bd",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## 6. Gradient Boosting (XGBoost/LightGBM style)\n",
    "\n",
    "**What it is:** Another ensemble method, but instead of building trees independently \n",
    "(like Random Forest), Gradient Boosting builds trees SEQUENTIALLY. Each new tree \n",
    "tries to correct the mistakes of previous trees.\n",
    "\n",
    "**How it works:**\n",
    "1. Build a simple model (often just predicting the average)\n",
    "2. Look at the errors this model makes\n",
    "3. Build a new model that specifically tries to predict these errors\n",
    "4. Add this new model to your ensemble\n",
    "5. Repeat hundreds of times\n",
    "\n",
    "**Why it's \"medium-low\" interpretability:**\n",
    "- **GOOD:** You can get feature importance (like Random Forest)\n",
    "- **BAD:** Even harder to interpret than Random Forest because trees are built to correct errors, not to be interpretable\n",
    "- **BAD:** The sequential nature makes it very hard to understand overall patterns\n",
    "\n",
    "**When you'd use it in ecology:**\n",
    "- When you need the highest accuracy possible\n",
    "- Kaggle competitions (it wins a lot of them)\n",
    "- When interpretability is less important than performance\n",
    "\n",
    "**In practice:** Gradient Boosting often achieves slightly better accuracy than \n",
    "Random Forest, but is harder to interpret and tune. It's also more prone to \n",
    "overfitting if you're not careful.\n",
    "\n",
    "**For ecology:** Random Forest is usually preferred unless you really need that \n",
    "extra 1-2% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b61d7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Fit Gradient Boosting\n",
    "# n_estimators = how many trees to build sequentially\n",
    "# learning_rate = how much each tree contributes (lower = more conservative)\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, \n",
    "                                     max_depth=3, random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"GRADIENT BOOSTING RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nNumber of trees: {gb_clf.n_estimators}\")\n",
    "print(f\"Learning rate: {gb_clf.learning_rate}\")\n",
    "print(f\"Accuracy on test set: {accuracy_gb:.3f} ({accuracy_gb*100:.1f}%)\")\n",
    "print(\"\\nDetailed Performance by Species:\")\n",
    "print(classification_report(y_test, y_pred_gb, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac500e99",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "---\n",
    "### INTERPRETABILITY ANALYSIS: Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a984dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importance_df_gb = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': gb_clf.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"GRADIENT BOOSTING FEATURE IMPORTANCE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nThese scores show which features were most important for reducing\")\n",
    "print(\"prediction error across the sequential ensemble.\\n\")\n",
    "print(importance_df_gb.to_string(index=False))\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(importance_df_gb['Feature'], importance_df_gb['Importance'], \n",
    "         color='darkorange', edgecolor='black')\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.title('Feature Importance in Gradient Boosting', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON: Random Forest vs Gradient Boosting Feature Importance\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Compare to Random Forest\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Random Forest': rf_clf.feature_importances_,\n",
    "    'Gradient Boosting': gb_clf.feature_importances_\n",
    "})\n",
    "print(\"\\n\", comparison_df.round(3).to_string(index=False))\n",
    "\n",
    "print(\"\\nThe rankings may differ between methods because they measure 'importance'\")\n",
    "print(\"differently. Random Forest: how often features are used for splits.\")\n",
    "print(\"Gradient Boosting: how much features reduce error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d62919c",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "**Key Takeaway for Gradient Boosting:**\n",
    "\n",
    "✓ **Can I explain what features matter most?** YES - feature importance scores\n",
    "✓ **Can I explain why a specific prediction was made?** NO - it's hundreds of correction steps\n",
    "✓ **Can I explain the general pattern?** NO - the sequential nature makes this very opaque\n",
    "\n",
    "**This is low-medium interpretability.** You can identify important features, but \n",
    "understanding the actual decision process is nearly impossible. Use this when \n",
    "accuracy is paramount and you can live with a black box (but can still point to \n",
    "important features for your paper).\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "============================================================================\n",
    "SECTION 4: LOW INTERPRETABILITY - SUPPORT VECTOR MACHINES\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2d5c14",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "---\n",
    "# PART 4: LOW INTERPRETABILITY - COMPLEX MODELS\n",
    "\n",
    "These models can achieve high accuracy but are much harder to interpret. You \n",
    "typically can't easily explain how they make decisions without using extra tools.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Support Vector Machine (SVM)\n",
    "\n",
    "**What it is:** SVM finds the \"best\" boundary (hyperplane) that separates classes. \n",
    "It tries to maximize the margin between classes - finding the widest possible \n",
    "\"street\" between groups.\n",
    "\n",
    "**How it works:** \n",
    "- In 2D: draws a line between classes with the maximum margin\n",
    "- In higher dimensions: creates a hyperplane\n",
    "- Can use \"kernels\" to handle non-linear boundaries (this makes it more powerful but less interpretable)\n",
    "\n",
    "**Why it's low interpretability:**\n",
    "- **No feature importance scores** by default\n",
    "- **Can't trace individual predictions** easily\n",
    "- **The \"kernel trick\"** (used for non-linear problems) makes it essentially a black box\n",
    "- The only interpretable part is which data points are \"support vectors\" (the critical points that define the boundary)\n",
    "\n",
    "**When you'd use it in ecology:**\n",
    "- Small datasets where it might outperform other methods\n",
    "- When you specifically need a maximum-margin classifier\n",
    "- Honestly, it's less popular in ecology than Random Forest or Neural Networks\n",
    "\n",
    "**Why you might NOT use it:**\n",
    "- Limited interpretability\n",
    "- Can be slow on large datasets\n",
    "- Requires feature scaling (preprocessing step)\n",
    "- Hyperparameter tuning can be tricky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVMs work better with scaled features, so let's scale first\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fit SVM\n",
    "# kernel='rbf' uses the radial basis function - good for non-linear problems\n",
    "# but makes the model a black box\n",
    "svm_clf = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "svm_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SUPPORT VECTOR MACHINE RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nKernel: {svm_clf.kernel}\")\n",
    "print(f\"Number of support vectors: {svm_clf.n_support_}\")\n",
    "print(f\"Accuracy on test set: {accuracy_svm:.3f} ({accuracy_svm*100:.1f}%)\")\n",
    "print(\"\\nDetailed Performance by Species:\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=target_names))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ABOUT SUPPORT VECTORS:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTotal support vectors: {sum(svm_clf.n_support_)}\")\n",
    "print(f\"Support vectors per class: {svm_clf.n_support_}\")\n",
    "print(\"\\nSupport vectors are the critical data points that define the decision\")\n",
    "print(\"boundary. They're the 'edges' of each class - the flowers closest to\")\n",
    "print(\"the boundary between species. Everything else is redundant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccf4802",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "---\n",
    "### INTERPRETABILITY ANALYSIS: What CAN we interpret?\n",
    "\n",
    "SVMs don't give us much to work with for interpretability. There are no \n",
    "coefficients, no feature importance, and no clear decision rules. Here's what \n",
    "we CAN look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2097ba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SVM INTERPRETABILITY LIMITATIONS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "What we DON'T get from SVMs:\n",
    "❌ Feature importance scores\n",
    "❌ Coefficients telling us direction of effects\n",
    "❌ Decision rules we can write down\n",
    "❌ Easy way to trace individual predictions\n",
    "\n",
    "What we DO get:\n",
    "✓ Which training samples are support vectors (the critical points)\n",
    "✓ Probability scores for predictions (if we enable probability=True)\n",
    "✓ Overall accuracy\n",
    "\n",
    "To make SVMs more interpretable, you'd need to use:\n",
    "- Permutation importance (test what happens when you shuffle each feature)\n",
    "- SHAP values (we'll show this technique with neural networks)\n",
    "- Partial dependence plots (show how predictions change with each feature)\n",
    "\n",
    "These are \"post-hoc\" interpretability methods - they're add-ons that try to\n",
    "explain what the black box is doing.\n",
    "\"\"\")\n",
    "\n",
    "# Let's at least show probability predictions\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PROBABILITY PREDICTIONS (First 5 Test Samples)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "y_pred_proba_svm = svm_clf.predict_proba(X_test_scaled)\n",
    "prob_df_svm = pd.DataFrame(y_pred_proba_svm[:5], columns=target_names)\n",
    "prob_df_svm['Predicted'] = [target_names[i] for i in y_pred_svm[:5]]\n",
    "prob_df_svm['True'] = [target_names[i] for i in y_test[:5]]\n",
    "\n",
    "print(\"\\n\", prob_df_svm.round(3).to_string(index=False))\n",
    "print(\"\\nThese probabilities tell us the model's confidence, but not WHY\")\n",
    "print(\"it reached these conclusions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f171c0e9",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "**Key Takeaway for SVM:**\n",
    "\n",
    "✗ **Can I explain what features matter most?** NO - not without extra analysis\n",
    "✗ **Can I explain why a specific prediction was made?** NO - it's a black box\n",
    "✗ **Can I explain the general pattern?** NO - especially with non-linear kernels\n",
    "\n",
    "**This is low interpretability.** SVMs can be accurate, but you're essentially \n",
    "trusting the algorithm without understanding its logic. In ecology research where \n",
    "you need to defend your methods, this is often unacceptable unless you add \n",
    "interpretability tools.\n",
    "\n",
    "**For ecology work:** Random Forests are usually preferred over SVMs because they \n",
    "offer similar accuracy with better interpretability.\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "============================================================================\n",
    "SECTION 5: VERY LOW INTERPRETABILITY - NEURAL NETWORKS\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a823f95",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "---\n",
    "# PART 5: LOWEST INTERPRETABILITY - NEURAL NETWORKS\n",
    "\n",
    "Neural networks are the most complex models we'll cover. They can learn incredibly \n",
    "intricate patterns, but they're essentially black boxes without special tools.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Neural Network (Multi-Layer Perceptron)\n",
    "\n",
    "**What it is:** A network of interconnected \"neurons\" (mathematical functions) \n",
    "organized in layers. Information flows from input → hidden layers → output. Each \n",
    "connection has a weight that's learned during training.\n",
    "\n",
    "**How it works:**\n",
    "- Input layer: your features\n",
    "- Hidden layers: transformations of features (the magic happens here)\n",
    "- Output layer: class probabilities\n",
    "- During training: weights are adjusted to minimize prediction errors using backpropagation\n",
    "\n",
    "**Why it's very low interpretability:**\n",
    "- **Thousands or millions of weights** - no way to interpret them all\n",
    "- **Hidden layers** transform features in complex, non-linear ways\n",
    "- **Interactions** between features are happening throughout the network\n",
    "- **No feature importance** by default\n",
    "- **Can't trace individual predictions** without specialized tools\n",
    "\n",
    "**When you'd use it in ecology:**\n",
    "- Image classification (e.g., camera trap photos, satellite imagery)\n",
    "- Genomic data analysis\n",
    "- Complex non-linear patterns that simpler models miss\n",
    "- When accuracy is critical and interpretability can be sacrificed\n",
    "\n",
    "**The tradeoff:** Neural networks can achieve the highest accuracy, but you're \n",
    "completely in the dark about HOW they work unless you use interpretability tools \n",
    "like SHAP values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad16a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Neural networks also work better with scaled features\n",
    "# (we already have X_train_scaled and X_test_scaled from SVM)\n",
    "\n",
    "# Fit neural network\n",
    "# hidden_layer_sizes=(100, 50) means 2 hidden layers with 100 and 50 neurons\n",
    "# This creates thousands of parameters!\n",
    "nn_clf = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, \n",
    "                       random_state=42, early_stopping=True)\n",
    "nn_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_nn = nn_clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_nn = accuracy_score(y_test, y_pred_nn)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"NEURAL NETWORK RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nArchitecture: {nn_clf.hidden_layer_sizes}\")\n",
    "print(f\"Number of iterations: {nn_clf.n_iter_}\")\n",
    "print(f\"Number of layers: {nn_clf.n_layers_}\")\n",
    "print(f\"Total parameters: ~{sum([layer.size for layer in nn_clf.coefs_])}\")\n",
    "print(f\"\\nAccuracy on test set: {accuracy_nn:.3f} ({accuracy_nn*100:.1f}%)\")\n",
    "print(\"\\nDetailed Performance by Species:\")\n",
    "print(classification_report(y_test, y_pred_nn, target_names=target_names))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"THE BLACK BOX:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nThis neural network has {nn_clf.n_layers_} layers and learned thousands\")\n",
    "print(\"of weights. Each weight represents the strength of a connection between neurons.\")\n",
    "print(\"\\nTrying to interpret these weights directly is like trying to understand\")\n",
    "print(\"how a brain works by looking at individual synapse strengths - it's\")\n",
    "print(\"technically possible but practically impossible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c85219",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "---\n",
    "### INTERPRETABILITY ANALYSIS: Using SHAP Values\n",
    "\n",
    "Since neural networks are black boxes, we need special tools to understand them. \n",
    "The most popular tool is **SHAP** (SHapley Additive exPlanations).\n",
    "\n",
    "**What SHAP does:** For any single prediction, it tells you how much each feature \n",
    "contributed. It's like decomposing a prediction into additive parts.\n",
    "\n",
    "**Example:** \n",
    "- Base prediction: 33% for each class (if you knew nothing)\n",
    "- Petal length adds +40% to setosa probability\n",
    "- Petal width adds -20% to setosa probability\n",
    "- Final: 53% probability for setosa\n",
    "\n",
    "This lets you say \"This flower was classified as setosa mainly because of its \n",
    "short petal length.\"\n",
    "\n",
    "Let's install and use SHAP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7886555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install shap if not already installed\n",
    "# You may need to run: pip install shap\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"SHAP NOT INSTALLED\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nTo install SHAP, run: pip install shap\")\n",
    "    print(\"\\nSkipping SHAP analysis for now. SHAP is an add-on interpretability\")\n",
    "    print(\"tool that helps explain black box models like neural networks.\")\n",
    "    print(\"\\nFor now, we'll just show what SHAP does conceptually.\")\n",
    "    SHAP_AVAILABLE = False\n",
    "\n",
    "if SHAP_AVAILABLE:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"SHAP VALUES ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nSHAP (SHapley Additive exPlanations) helps us understand individual\")\n",
    "    print(\"predictions from our neural network. It's based on game theory.\")\n",
    "    print(\"\\nThis might take a moment to compute...\")\n",
    "    \n",
    "    # Create a SHAP explainer\n",
    "    # We'll use a subset of training data as background for speed\n",
    "    explainer = shap.KernelExplainer(nn_clf.predict_proba, X_train_scaled[:50])\n",
    "    \n",
    "    # Get SHAP values for test set (just first 10 for speed)\n",
    "    shap_values = explainer.shap_values(X_test_scaled[:10])\n",
    "    \n",
    "    # SHAP values is a list (one array per class)\n",
    "    # Let's explain the first test sample\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXAMPLE: Explaining One Prediction\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    sample_idx = 0\n",
    "    print(f\"\\nFlower measurements: {dict(zip(feature_names, X_test[sample_idx]))}\")\n",
    "    print(f\"True species: {target_names[y_test[sample_idx]]}\")\n",
    "    print(f\"Predicted species: {target_names[y_pred_nn[sample_idx]]}\")\n",
    "    print(f\"Prediction probabilities: {nn_clf.predict_proba(X_test_scaled[sample_idx:sample_idx+1])[0]}\")\n",
    "    \n",
    "    print(\"\\nSHAP values (contribution to each class):\")\n",
    "    for i, species in enumerate(target_names):\n",
    "        print(f\"\\n{species}:\")\n",
    "        shap_for_class = shap_values[i][sample_idx]\n",
    "        feature_contrib = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'SHAP Value': shap_for_class\n",
    "        }).sort_values('SHAP Value', key=abs, ascending=False)\n",
    "        print(feature_contrib.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"INTERPRETATION:\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\"\"\n",
    "SHAP values tell you:\n",
    "- Positive SHAP = this feature pushes prediction TOWARD this class\n",
    "- Negative SHAP = this feature pushes prediction AWAY from this class\n",
    "- Magnitude = how strong the effect is\n",
    "\n",
    "So if petal length has SHAP = +0.3 for setosa and -0.4 for virginica,\n",
    "it means petal length is evidence FOR setosa and AGAINST virginica for\n",
    "this particular flower.\n",
    "\n",
    "This is how we make neural networks interpretable! Without SHAP, we'd\n",
    "just have a prediction with no explanation.\n",
    "    \"\"\")\n",
    "    \n",
    "    # Create summary plot\n",
    "    print(\"\\nGenerating SHAP summary plot...\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.summary_plot(shap_values[0], X_test_scaled[:10], \n",
    "                      feature_names=feature_names, show=False)\n",
    "    plt.title('SHAP Values for Setosa Class (First 10 Test Samples)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nIn the plot above, each dot is one flower. Color shows feature value\")\n",
    "    print(\"(red=high, blue=low). Position shows SHAP value (impact on prediction).\")\n",
    "\n",
    "else:\n",
    "    # If SHAP not available, explain conceptually\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"INTERPRETABILITY FOR NEURAL NETWORKS (Conceptual)\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\"\"\n",
    "Neural networks are black boxes, but we have tools to understand them:\n",
    "\n",
    "1. **SHAP VALUES** (most popular):\n",
    "   - Breaks down each prediction into feature contributions\n",
    "   - Tells you \"this flower was classified as setosa because...\"\n",
    "   - Based on game theory (Shapley values)\n",
    "   - Example: \"Petal length (+0.3), Petal width (-0.1), Sepal length (+0.05)...\"\n",
    "\n",
    "2. **LIME** (Local Interpretable Model-agnostic Explanations):\n",
    "   - Fits a simple model (like linear regression) locally around one prediction\n",
    "   - Shows which features mattered for that specific prediction\n",
    "   - Less theoretically grounded than SHAP but faster\n",
    "\n",
    "3. **Permutation Importance**:\n",
    "   - Shuffle one feature and see how much accuracy drops\n",
    "   - Tells you global feature importance (not individual predictions)\n",
    "\n",
    "4. **Partial Dependence Plots**:\n",
    "   - Show how predictions change as you vary one feature\n",
    "   - Useful for understanding general patterns\n",
    "\n",
    "5. **Layer Activation Visualization**:\n",
    "   - For image data: visualize what each layer \"sees\"\n",
    "   - Less useful for tabular data like iris measurements\n",
    "\n",
    "These are ALL add-on tools. The neural network itself gives you nothing\n",
    "for interpretability. This is why we call it a black box.\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15ecd06",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "**Key Takeaway for Neural Networks:**\n",
    "\n",
    "✗ **Can I explain what features matter most?** NO - not without SHAP/LIME/other tools\n",
    "✗ **Can I explain why a specific prediction was made?** NO - not without SHAP/LIME\n",
    "✗ **Can I explain the general pattern?** NO - it's thousands of non-linear transformations\n",
    "\n",
    "**This is the lowest interpretability.** You MUST use interpretability tools like \n",
    "SHAP if you want to explain predictions. The upside is neural networks can learn \n",
    "incredibly complex patterns that simpler models miss.\n",
    "\n",
    "**For ecology:** Only use neural networks when:\n",
    "1. You have enough data (thousands of samples)\n",
    "2. The problem is complex enough to need them\n",
    "3. You're willing to use interpretability tools\n",
    "4. Accuracy is more important than transparency\n",
    "\n",
    "Otherwise, stick with Random Forests or simpler models.\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "============================================================================\n",
    "SECTION 6: UNSUPERVISED LEARNING\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd1b763",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "---\n",
    "# PART 6: UNSUPERVISED LEARNING\n",
    "\n",
    "So far we've covered SUPERVISED learning - where we have labels (species) and \n",
    "predict them. Now let's cover UNSUPERVISED learning - where we look for patterns \n",
    "without using labels.\n",
    "\n",
    "**Why this matters in ecology:**\n",
    "- Discovering unknown groups in your data\n",
    "- Reducing dimensionality for visualization\n",
    "- Finding patterns without preconceived categories\n",
    "- Exploratory data analysis\n",
    "\n",
    "---\n",
    "\n",
    "## 9. K-Means Clustering\n",
    "\n",
    "**What it is:** Groups data into K clusters based on similarity. It tries to find \n",
    "K \"cluster centers\" such that each point is closest to one center.\n",
    "\n",
    "**How it works:**\n",
    "1. Randomly place K cluster centers\n",
    "2. Assign each point to its nearest center\n",
    "3. Move each center to the average of its assigned points\n",
    "4. Repeat steps 2-3 until convergence\n",
    "\n",
    "**Why it's moderately interpretable:**\n",
    "- You can see the cluster centers (the \"average\" member of each cluster)\n",
    "- You can see which features separate clusters\n",
    "- You can visualize clusters in 2D/3D\n",
    "- BUT: the clusters might not correspond to real biological groups\n",
    "\n",
    "**When you'd use it in ecology:**\n",
    "- Discovering functional groups of species\n",
    "- Finding habitat types from environmental data\n",
    "- Clustering genotypes\n",
    "- Exploratory analysis before hypothesis testing\n",
    "\n",
    "**Limitation:** You must specify K (number of clusters) in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230196ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# For clustering, we'll use scaled data and ignore labels\n",
    "# (that's what makes it unsupervised - we don't use y)\n",
    "\n",
    "# Fit K-Means with 3 clusters (we know there are 3 species, but pretend we don't)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(X_train_scaled)\n",
    "\n",
    "# Also get clusters for test set\n",
    "cluster_labels_test = kmeans.predict(X_test_scaled)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"K-MEANS CLUSTERING RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nNumber of clusters: {kmeans.n_clusters}\")\n",
    "print(f\"Iterations to converge: {kmeans.n_iter_}\")\n",
    "\n",
    "# Show cluster centers (in scaled space)\n",
    "centers_scaled = kmeans.cluster_centers_\n",
    "# Transform back to original scale for interpretation\n",
    "centers_original = scaler.inverse_transform(centers_scaled)\n",
    "\n",
    "centers_df = pd.DataFrame(centers_original, columns=feature_names)\n",
    "centers_df.index = [f'Cluster {i}' for i in range(kmeans.n_clusters)]\n",
    "\n",
    "print(\"\\nCluster Centers (average values for each cluster):\")\n",
    "print(centers_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57635324",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "**Important:** K-Means doesn't know about species labels. It just found 3 groups \n",
    "based on similarity. Let's see how well these clusters correspond to actual species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare clusters to true species labels\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARING CLUSTERS TO TRUE SPECIES\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nRemember: K-Means doesn't know the species labels. Let's see if the\")\n",
    "print(\"clusters it found match the biological species.\\n\")\n",
    "\n",
    "# Create a confusion matrix: true species vs. assigned clusters\n",
    "cluster_species_matrix = pd.crosstab(\n",
    "    pd.Series(y_train, name='True Species').map({i: target_names[i] for i in range(3)}),\n",
    "    pd.Series(cluster_labels, name='Assigned Cluster')\n",
    ")\n",
    "\n",
    "print(cluster_species_matrix)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Each row is a true species. Each column is a cluster found by K-Means.\n",
    "\n",
    "Perfect clustering would have each species entirely in one cluster (only one\n",
    "number per row is non-zero).\n",
    "\n",
    "If clusters match species well, it means the species are morphologically\n",
    "distinct enough to be discovered without labels - they form natural groups.\n",
    "\n",
    "If clusters don't match species, it could mean:\n",
    "- Species are morphologically similar (hard to separate)\n",
    "- Need different features to distinguish them\n",
    "- Clusters represent something other than species (maybe ecological functions)\n",
    "\"\"\")\n",
    "\n",
    "# Visualize clusters in 2D (using first 2 principal components for visualization)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_viz = PCA(n_components=2)\n",
    "X_pca = pca_viz.fit_transform(X_train_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot 1: Clusters found by K-Means\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, \n",
    "                      cmap='viridis', s=50, alpha=0.6, edgecolor='black')\n",
    "plt.scatter(pca_viz.transform(centers_scaled)[:, 0], \n",
    "            pca_viz.transform(centers_scaled)[:, 1],\n",
    "            c='red', marker='X', s=200, edgecolor='black', linewidths=2,\n",
    "            label='Cluster Centers')\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.title('K-Means Clusters', fontsize=12, fontweight='bold')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.legend()\n",
    "\n",
    "# Plot 2: True species labels\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter2 = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_train, \n",
    "                       cmap='viridis', s=50, alpha=0.6, edgecolor='black')\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.title('True Species', fontsize=12, fontweight='bold')\n",
    "cbar = plt.colorbar(scatter2, ticks=[0, 1, 2])\n",
    "cbar.set_ticklabels(target_names)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nThe plots above show the same data colored two ways:\")\n",
    "print(\"Left: By K-Means cluster assignment\")\n",
    "print(\"Right: By true species\")\n",
    "print(\"\\nIf the colors match up well, K-Means successfully discovered the species!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a47ea23",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "**Key Takeaway for K-Means:**\n",
    "\n",
    "✓ **Can I explain what features matter most?** SOMEWHAT - look at cluster centers\n",
    "✓ **Can I explain why a specific point is in a cluster?** YES - it's closest to that center\n",
    "✓ **Can I explain the general pattern?** YES - the centers describe each cluster\n",
    "\n",
    "**This is moderately interpretable.** You can understand what each cluster represents \n",
    "by looking at its center. The main challenge is that clusters might not match \n",
    "your biological expectations - they're just mathematical groupings.\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "============================================================================\n",
    "PRINCIPAL COMPONENT ANALYSIS (PCA)\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8b7a6c",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## 10. Principal Component Analysis (PCA)\n",
    "\n",
    "**What it is:** A dimensionality reduction technique. It finds new axes (principal \n",
    "components) that capture the most variation in your data. You can use these to \n",
    "visualize high-dimensional data in 2D/3D.\n",
    "\n",
    "**How it works:**\n",
    "1. Find the direction of maximum variance in your data (PC1)\n",
    "2. Find the direction of second-most variance, perpendicular to PC1 (PC2)\n",
    "3. Continue for as many dimensions as you want\n",
    "4. Project data onto these new axes\n",
    "\n",
    "**Why it's highly interpretable:**\n",
    "- Each PC is a linear combination of original features\n",
    "- You can see which features contribute to each PC\n",
    "- You can visualize patterns in low dimensions\n",
    "- Commonly used in exploratory analysis\n",
    "\n",
    "**When you'd use it in ecology:**\n",
    "- Visualizing complex trait data\n",
    "- Reducing correlated variables (e.g., multiple climate variables)\n",
    "- Exploratory analysis before modeling\n",
    "- Identifying major axes of variation in communities\n",
    "\n",
    "**It's so common in ecology that it has special names:** \n",
    "- Ordination\n",
    "- Eigenanalysis  \n",
    "- Sometimes called \"multivariate analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee2bbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Fit PCA (we'll keep all 4 components to understand them all)\n",
    "pca = PCA(n_components=4)\n",
    "X_pca_full = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PRINCIPAL COMPONENT ANALYSIS (PCA) RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Show variance explained\n",
    "print(\"\\nVariance explained by each component:\")\n",
    "var_explained_df = pd.DataFrame({\n",
    "    'Component': [f'PC{i+1}' for i in range(pca.n_components_)],\n",
    "    'Variance Explained': pca.explained_variance_ratio_,\n",
    "    'Cumulative Variance': np.cumsum(pca.explained_variance_ratio_)\n",
    "})\n",
    "print(var_explained_df.round(4).to_string(index=False))\n",
    "\n",
    "print(f\"\\nFirst 2 components explain {np.sum(pca.explained_variance_ratio_[:2])*100:.1f}%\")\n",
    "print(\"of total variance. This is why we can visualize data well in 2D!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe6d98e",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "**Understanding variance explained:**\n",
    "- PC1 captures the most variation in the data\n",
    "- PC2 captures the second most (and is perpendicular to PC1)\n",
    "- Together, first 2 PCs often capture 80-90% of variation\n",
    "- This means we can plot data in 2D without losing much information\n",
    "\n",
    "Now let's see what each component represents in terms of original features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ad9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show component loadings (how each feature contributes to each PC)\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    columns=[f'PC{i+1}' for i in range(pca.n_components_)],\n",
    "    index=feature_names\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PCA LOADINGS (Feature Contributions to Each Component)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nThese show how much each original feature contributes to each PC.\")\n",
    "print(\"Higher magnitude = more important for that component.\\n\")\n",
    "print(loadings.round(3))\n",
    "\n",
    "# Visualize loadings for first 2 PCs\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    pc_name = f'PC{i+1}'\n",
    "    loadings_sorted = loadings[pc_name].abs().sort_values(ascending=True)\n",
    "    colors = ['red' if x < 0 else 'blue' for x in loadings[pc_name][loadings_sorted.index]]\n",
    "    ax.barh(range(len(loadings_sorted)), loadings[pc_name][loadings_sorted.index], color=colors)\n",
    "    ax.set_yticks(range(len(loadings_sorted)))\n",
    "    ax.set_yticklabels(loadings_sorted.index)\n",
    "    ax.set_xlabel('Loading Value')\n",
    "    ax.set_title(f'{pc_name} Loadings', fontweight='bold')\n",
    "    ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Interpret PC1\n",
    "pc1_loadings = loadings['PC1'].abs().sort_values(ascending=False)\n",
    "print(f\"\\nPC1 (explains {pca.explained_variance_ratio_[0]*100:.1f}% of variance):\")\n",
    "print(f\"  → Dominated by: {pc1_loadings.index[0]} (loading: {loadings['PC1'][pc1_loadings.index[0]]:.3f})\")\n",
    "print(f\"  → Also important: {pc1_loadings.index[1]} (loading: {loadings['PC1'][pc1_loadings.index[1]]:.3f})\")\n",
    "print(\"  → This component seems to represent overall flower SIZE\")\n",
    "\n",
    "# Interpret PC2\n",
    "pc2_loadings = loadings['PC2'].abs().sort_values(ascending=False)\n",
    "print(f\"\\nPC2 (explains {pca.explained_variance_ratio_[1]*100:.1f}% of variance):\")\n",
    "print(f\"  → Dominated by: {pc2_loadings.index[0]} (loading: {loadings['PC2'][pc2_loadings.index[0]]:.3f})\")\n",
    "print(f\"  → Also important: {pc2_loadings.index[1]} (loading: {loadings['PC2'][pc2_loadings.index[1]]:.3f})\")\n",
    "print(\"  → This component seems to represent flower SHAPE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424cc8f6",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "**What PCA tells us biologically:**\n",
    "\n",
    "The principal components often have biological interpretations:\n",
    "- PC1 might represent overall SIZE (all measurements loading similarly)\n",
    "- PC2 might represent SHAPE (petals vs sepals loading differently)\n",
    "- Higher PCs capture more subtle variation\n",
    "\n",
    "This is why PCA is so popular in ecology - it helps you understand the main \n",
    "axes of biological variation in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c7636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data in PC space, colored by species\n",
    "pca_viz_final = PCA(n_components=2)\n",
    "X_pca_2d = pca_viz_final.fit_transform(X_train_scaled)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i, species in enumerate(target_names):\n",
    "    mask = y_train == i\n",
    "    plt.scatter(X_pca_2d[mask, 0], X_pca_2d[mask, 1], \n",
    "                label=species, s=100, alpha=0.6, edgecolor='black')\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca_viz_final.explained_variance_ratio_[0]*100:.1f}% variance)', fontsize=12)\n",
    "plt.ylabel(f'PC2 ({pca_viz_final.explained_variance_ratio_[1]*100:.1f}% variance)', fontsize=12)\n",
    "plt.title('Iris Dataset in Principal Component Space', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nThis is the classic iris visualization! Each species occupies a\")\n",
    "print(\"different region of PC space. This shows that species differ in\")\n",
    "print(\"both size (PC1) and shape (PC2).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47fca52",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "**Key Takeaway for PCA:**\n",
    "\n",
    "✓ **Can I explain what features matter most?** YES - loadings show contributions\n",
    "✓ **Can I explain patterns in the data?** YES - PCs have biological interpretations\n",
    "✓ **Can I visualize high-dimensional data?** YES - project onto 2D/3D\n",
    "\n",
    "**This is highly interpretable.** PCA is a linear transformation with clear \n",
    "mathematical meaning. It's one of the most interpretable unsupervised methods \n",
    "and is ubiquitous in ecology.\n",
    "\n",
    "**Limitation:** It only captures linear patterns. If your data has non-linear \n",
    "structure, techniques like t-SNE or UMAP might be better (but less interpretable).\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "============================================================================\n",
    "FINAL COMPARISON AND SUMMARY\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b17f82",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "---\n",
    "# FINAL SUMMARY: Model Comparison\n",
    "\n",
    "Let's compare all the supervised learning models we tested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0cd04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary comparison\n",
    "results_summary = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'Logistic Regression',\n",
    "        'Linear Regression',\n",
    "        'Decision Tree',\n",
    "        'Naive Bayes',\n",
    "        'Random Forest',\n",
    "        'Gradient Boosting',\n",
    "        'Support Vector Machine',\n",
    "        'Neural Network'\n",
    "    ],\n",
    "    'Accuracy': [\n",
    "        accuracy_log,\n",
    "        None,  # This was regression, not classification\n",
    "        accuracy_tree,\n",
    "        accuracy_nb,\n",
    "        accuracy_rf,\n",
    "        accuracy_gb,\n",
    "        accuracy_svm,\n",
    "        accuracy_nn\n",
    "    ],\n",
    "    'Interpretability': [\n",
    "        'Very High',\n",
    "        'Very High',\n",
    "        'High',\n",
    "        'Medium',\n",
    "        'Medium',\n",
    "        'Medium-Low',\n",
    "        'Low',\n",
    "        'Very Low'\n",
    "    ],\n",
    "    'Feature Importance': [\n",
    "        'Coefficients',\n",
    "        'Coefficients',\n",
    "        'Built-in',\n",
    "        'Class statistics',\n",
    "        'Built-in',\n",
    "        'Built-in',\n",
    "        'Need extra tools',\n",
    "        'Need SHAP/LIME'\n",
    "    ],\n",
    "    'When to Use': [\n",
    "        'Need transparency',\n",
    "        'Continuous targets',\n",
    "        'Want decision rules',\n",
    "        'Quick baseline',\n",
    "        'Default choice',\n",
    "        'Max accuracy',\n",
    "        'Rarely in ecology',\n",
    "        'Complex patterns + large data'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n\", results_summary.to_string(index=False))\n",
    "\n",
    "# Visualize accuracy vs interpretability\n",
    "models_for_viz = results_summary[results_summary['Accuracy'].notna()].copy()\n",
    "\n",
    "# Map interpretability to numeric scale\n",
    "interp_map = {\n",
    "    'Very High': 5,\n",
    "    'High': 4,\n",
    "    'Medium': 3,\n",
    "    'Medium-Low': 2.5,\n",
    "    'Low': 2,\n",
    "    'Very Low': 1\n",
    "}\n",
    "models_for_viz['Interp_Score'] = models_for_viz['Interpretability'].map(interp_map)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(models_for_viz['Interp_Score'], models_for_viz['Accuracy'], \n",
    "            s=200, alpha=0.6, edgecolor='black', linewidth=2)\n",
    "\n",
    "for idx, row in models_for_viz.iterrows():\n",
    "    plt.annotate(row['Model'], \n",
    "                (row['Interp_Score'], row['Accuracy']),\n",
    "                xytext=(5, 5), textcoords='offset points',\n",
    "                fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.xlabel('Interpretability Score', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('The Interpretability-Accuracy Tradeoff', fontsize=14, fontweight='bold')\n",
    "plt.xlim(0.5, 5.5)\n",
    "plt.ylim(0.9, 1.01)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Add annotations\n",
    "plt.axhline(y=0.95, color='green', linestyle='--', alpha=0.3, label='95% accuracy threshold')\n",
    "plt.axvline(x=3, color='red', linestyle='--', alpha=0.3, label='Medium interpretability')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459967ea",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "---\n",
    "# KEY TAKEAWAYS FOR ECOLOGY RESEARCH\n",
    "\n",
    "## 1. **The Interpretability Spectrum**\n",
    "\n",
    "**Most Interpretable (Use these when you need to explain):**\n",
    "- Logistic/Linear Regression: Coefficients tell the whole story\n",
    "- Decision Trees: Visual flowcharts anyone can follow\n",
    "- PCA: Clear feature contributions\n",
    "\n",
    "**Medium Interpretability (Good balance for most ecology work):**\n",
    "- Random Forest: Feature importance + decent accuracy\n",
    "- Naive Bayes: Class statistics + probabilities\n",
    "\n",
    "**Least Interpretable (Use only when accuracy is critical):**\n",
    "- Neural Networks: Need SHAP/LIME to explain anything\n",
    "- SVMs: Black boxes without extra tools\n",
    "\n",
    "## 2. **Recommendations for Ecology Students**\n",
    "\n",
    "**For your thesis/dissertation:**\n",
    "- **Start with simple models** (logistic regression, decision trees)\n",
    "- Justify why you need complexity if you use it\n",
    "- Always include feature importance or interpretability analysis\n",
    "- Be ready to defend your modeling choices\n",
    "\n",
    "**For Species Distribution Models (SDMs):**\n",
    "- MaxEnt or Random Forest are standard\n",
    "- Include response curves or partial dependence plots\n",
    "- Show which environmental variables matter most\n",
    "\n",
    "**For Classification Problems:**\n",
    "- Try Random Forest first (good accuracy + some interpretability)\n",
    "- Compare to simpler baseline (logistic regression)\n",
    "- Report both accuracy AND interpretability\n",
    "\n",
    "**For Exploratory Analysis:**\n",
    "- Always start with PCA\n",
    "- Use K-Means to discover groups\n",
    "- Visualize before modeling\n",
    "\n",
    "## 3. **The Accuracy-Interpretability Tradeoff**\n",
    "\n",
    "On this iris dataset:\n",
    "- Simple models (logistic regression, decision trees): 93-97% accuracy, fully interpretable\n",
    "- Complex models (neural networks, SVM): 97-100% accuracy, require extra tools\n",
    "\n",
    "**That 3-7% accuracy gain often isn't worth the loss of interpretability!**\n",
    "\n",
    "Unless you're doing:\n",
    "- Image classification (camera traps)\n",
    "- Genomic prediction\n",
    "- Complex spatial patterns\n",
    "\n",
    "...stick with Random Forests or simpler models.\n",
    "\n",
    "## 4. **Red Flags in Papers**\n",
    "\n",
    "Be skeptical when you see:\n",
    "- Complex ML with no feature importance reported\n",
    "- Neural networks with no interpretability analysis\n",
    "- No comparison to simpler baseline models\n",
    "- No biological interpretation of what was learned\n",
    "\n",
    "## 5. **Tools for Making Black Boxes Interpretable**\n",
    "\n",
    "If you MUST use complex models:\n",
    "- **SHAP values**: Explain individual predictions\n",
    "- **Partial dependence plots**: Show feature relationships\n",
    "- **Permutation importance**: Global feature importance\n",
    "- Always validate that patterns make biological sense!\n",
    "\n",
    "---\n",
    "\n",
    "# FINAL THOUGHT\n",
    "\n",
    "**\"Everything should be made as simple as possible, but no simpler.\" - Einstein**\n",
    "\n",
    "Apply this to ML:\n",
    "- Use the simplest model that answers your question well\n",
    "- Add complexity only when justified by your data and question\n",
    "- Always prioritize interpretability in ecology unless you have a very good reason not to\n",
    "\n",
    "Your reviewers, committee, and readers will thank you for being able to \n",
    "understand and trust your methods!\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"NOTEBOOK COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "You now have a complete reference for:\n",
    "✓ Major ML algorithms from most to least interpretable\n",
    "✓ How to implement each algorithm\n",
    "✓ How to evaluate performance\n",
    "✓ How to interpret results\n",
    "✓ When to use each method in ecology research\n",
    "\n",
    "Good luck with your lab meeting presentation!\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
